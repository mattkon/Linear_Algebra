# Matthew Konyndyk
# Math 343 Winter 2017
# Final Project Part 2






### DESCRIPTION OF ASSIGNMENT ######################################################################

# Part 2: Use some of the functions from your library, for an appropriately given input matrix A, and
# 1. Implement the GMRES algorithm with restart (provided in a separate .pdf file).
# 2. Perform study when you vary mmax = 5, 10, 15, ... the maximal number of steps allowed in the algorithm, and document the total number of iterations and total time to convergence for a given tolerance (and a given matrix). Write your conclusions from the study.

### BACKGROUND INFORMATION ON LEAST SQUARES ########################################################

# Least Squares: if A*x=b has no solution, you can find the least squares approximation using the formula (A^T)*A*(x`)=(A^T)*b
# This will minimize the distance ||b-A*x`|| betwen the least squares solution and the solution we wanted.
# Note - A*(x`) is the projection of b onto the column space of A.

# Gram Schmidt: Given a Matrix with arbitray basis, Gram Schmidt creates an orthonormal basis.

# QR decomposition: Q - Orthogonal Matrix, R - Upper Triangular Matrix; R = (Q^T)*M
# Using QR to solve least squares: R*x = (Q^T)*b


### GMRES ALGORITHM: An Iterative Least Squares Algorithm ##########################################

# credit to http://stackoverflow.com/questions/37962271/whats-wrong-with-my-gmres-implementation for helping me understand how to implement this algorithm.

# Krylov Subspace - the order-r Krylov subspace generated by an n-by-n matrix A and a vector b of dimension n is the linear subspace spanned by the images of b under the first r powers of A (starting from  A^{0}=I), that is the span {b,(A)b,(A^2)b,...,(A^(r-1))b} https://en.wikipedia.org/wiki/Krylov_subspace

# Arnoldi Iteration - an eigenvalue algorithm and an important example of iterative methods. Arnoldi finds the eigenvalues of general (possibly non-Hermitian) matrices. Arnoldi belongs to a class of linear algebra algorithms (based on the idea of Krylov subspaces) that give a partial result after a relatively small number of iterations. Arnoldi iteration is a typical large sparse matrix algorithm: It does not access the elements of the matrix directly, but rather makes the matrix map vectors and makes its conclusions from their images. This is the motivation for building the Krylov subspace. https://en.wikipedia.org/wiki/Arnoldi_iteration

# GMRES - generalized minimal residual method (GMRES) is an iterative method for the numerical solution of a nonsymmetric system of linear equations. The method approximates the solution by the vector in a Krylov subspace with minimal residual. The Arnoldi iteration is used to find this vector. https://en.wikipedia.org/wiki/Generalized_minimal_residual_method

# We start with an initial approximation guess x0 (x0 is arbitray, I begin with zeros.) we also have input tolerance (e) and number of iterations(m_max)

# The algorithm will stop once ||b-A*x`|| < e, or m_max has been reached
import math
import random
import time
import csv
import numpy as np
import scipy as sp


#writes a square sparse row matrix's data to a csv file using i, j, and data lists.
def write_csv(path,i,j,data,mtx_size):
    csv_file = open(path, 'wt')
    writer = csv.writer(csv_file)
    writer.writerow( ('i', 'j', 'data',len(data),mtx_size) ) #len(data) is used for reading
    for x in range(0,len(i)):
        row = [i[x],j[x],data[x]]
        writer.writerow(row)
    csv_file.close()



#loads the i, j, and data vectors from a square sparse row matrix.
def load_csv(path):
    csv_file = open(path, 'rt')
    reader = csv.reader(csv_file)
    array = reader.next() #first line is header info
    num_entries = int(array[3])
    mtx_size = int(array[4])
    x = 0
    i,j,data = [0]*(num_entries), [0]*(num_entries), [0]*(num_entries)
    while num_entries > 0:
        array = reader.next()
        i[x] = int(array[0])
        j[x] = int(array[1])
        data[x] = float(array[2])
        num_entries -= 1
        x+=1
    csv_file.close()
    return i,j,data,mtx_size



def assemble_sparse_matrix(i,j,data,size):
    matrix = [[0 for x in range(size)] for y in range(size)] #creates empty array of the proper dimensions
    for x in range (0,len(i)):
        t,v = i[x] - 1, j[x] - 1
        matrix[t][v] = float(data[x])
    return matrix





def GMRES_(A, b, x0, e, m_max, restart): #Finds numerical solution to a nonsymmetric system of linear equations. Useful for sparse matrices, because of the relatively low  systemmemory it requires.
    
    #initialize values
    x = [] # initializes return vector
    q = [0] * (m_max) # initializes Krylov subspace
    h = np.zeros((m_max + 1, m_max)) #used in Arnoldi iteration?
    restartsleft = restart
    
    #begin
    while restartsleft > 0:
        r = b - np.asarray(sp.dot(A, x0)).reshape(-1) # initial residual, reshaped to a vector
        x.append(r)
        q[0] = r / np.linalg.norm(r) #initial residual normalized
        
        #The Arnoldi iteration uses the stabilized Gram Schmidt process to find orthonormal vectors, q1, q2, q3, ..., called the Arnoldi vectors, such that for every n, q1, ..., qn span the Krylov subspace. https://en.wikipedia.org/wiki/Arnoldi_iteration
        
        for k in range(m_max): #changes from wikipedia algorithm: q[k] = q[k-1], y = q[k]
            y = np.asarray(sp.dot(A, q[k])).reshape(-1) #A.normalized residual
            for j in range(k):
                h[j, k] = np.dot(q[j], y) #fills out the m+1 x m matrix with q(j).q(k)
                y = y - h[j, k] * q[j]
            h[k + 1, k] = np.linalg.norm(y)
            if (h[k + 1, k] != 0 and k != m_max - 1): q[k + 1] = y / h[k + 1, k] #q(k) = q(k)/h(k,k-1)
            
            c = np.zeros(m_max + 1)
            c[0] = np.linalg.norm(r) #c is [norm(r), 0, 0, ... 0]
            result = np.linalg.lstsq(h, c)[0]
            x.append(np.dot(np.asarray(q).transpose(), result) + x0)
        
        restartsleft -= 1
        x0 = x[m_max] #resets x0 before next restart
    
    return x, restart-restartsleft



def generate_sparse_matrix(entries, size, location):
    i,j,data = [0]*(entries), [0]*(entries), [0]*(entries)
    for x in range (0,entries):
        i[x] = random.randint (0,size-1)
        j[x] = random.randint (0,size-1)
        data[x] = random.randint(1,9)
    write_csv(location,i,j,data,size) #writes to csv file



#GMRES ALGORITHM

### SETUP ###
#Load mtx_494, mtx_662, or mtx_1138
location = '1138.csv'
i,j,data,size = load_csv(location)
mtx_x = assemble_sparse_matrix(i,j,data,size)
mtx_x = np.matrix(mtx_x) #creates a sparse matrix from i, j, data vectors
print '\n', 'Matrix', location
print mtx_x

#Perform GMRES with b = random vector
b = np.random.random(size) #creates random solution vector
for x in range (0,size): b[x] = random.randint (0,1)
print '\n', 'vector b'
print b

#1) mmax = 5, e = 0.001, number of iterations it took, time to convergence
e = 1e-03 #tolerances
m_max = 5
restarts=100
iterations=20
for x in range (0,size): b[x] = random.randint (0,1) #modifies solution vector to ints 0-9
x0 = np.zeros(size) #initial Approximation
start = time.time() #start timer
result, rest = GMRES_(mtx_x, b, x0, e, m_max, restarts) #(A, b, x0, e, m_max, initial_restarts):
end = time.time() #end timer
print '\n', 'Trial 1'
print 'Iterations in each cycle: ', m_max
print 'Restarts: ',  rest
print 'Total iterations: ', rest*m_max
print 'Time to coverge: ', end - start, '[s]'
print 'Final solution vector: '
print result[m_max]

#2) m_max = 10, e = 0.001
m_max = 10
start = time.time() #start timer
result,restarts_left = GMRES_(mtx_x, b, x0, e, m_max, restarts) #(A, b, x0, e, m_max, initial_restarts):
end = time.time() #end timer
print '\n', 'Trial 2'
print 'Iterations in each cycle: ', m_max
print 'Restarts: ',  rest
print 'Total iterations: ', rest*m_max
print 'Time to converge: ', end - start, '[s]'
print 'Final solution vector: '
print result[m_max]

#3) mmax = 25, e = 0.001
m_max = 25
start = time.time() #start timer
result,restarts_left = GMRES_(mtx_x, b, x0, e, m_max, restarts) #(A, b, x0, e, m_max, initial_restarts):
end = time.time() #end timer
print '\n', 'Trial 3'
print 'Iterations in each cycle: ', m_max
print 'Restarts: ',  rest
print 'Total iterations: ', rest*m_max
print 'Time to converge: ', end - start, '[s]'
print 'Final solution vector: '
print result[m_max]


#4) mmax = 50, e = 0.001
m_max = 50
start = time.time() #start timer
result,restarts_left = GMRES_(mtx_x, b, x0, e, m_max, restarts) #(A, b, x0, e, m_max, initial_restarts):
end = time.time() #end timer
print '\n', 'Trial 4'
print 'Iterations in each cycle: ', m_max
print 'Restarts: ',  rest
print 'Total iterations: ', rest*m_max
print 'Time to converge: ', end - start, '[s]'
print 'Final solution vector: '
print result[m_max]


#5) mmax = 100, e = 0.001
m_max = 100
start = time.time() #start timer
result,restarts_left = GMRES_(mtx_x, b, x0, e, m_max, restarts) #(A, b, x0, e, m_max, initial_restarts):
end = time.time() #end timer
print '\n', 'Trial 5'
print 'Iterations in each cycle: ', m_max
print 'Restarts: ',  rest
print 'Total iterations: ', rest*m_max
print 'Time to converge: ', end - start, '[s]'
print 'Final solution vector: '
print result[m_max]
